---
title: "Predictors of Depression During the Covid-19 Pandemic" 
subtitle: "K-Medoids Clustering"
author: "Sarka Tesarova, Ondrej Pekacek, Alessandro Porrovecchio"
date: "Last edited `r format (Sys.time(),'%d. %m. %Y')`"
output:
  html_document: 
    toc: yes
    toc_depth: 2
    toc_float: true
    number_sections: true
    theme: readable
    code_folding: hide
    code_download: true
    includes:
      in_header: header.html
---


```{r loading packages and dataset, message=FALSE, warning=FALSE}
# Package names
packages <- c("dplyr", "tidyr", "NbClust", "factoextra", "cluster", "clValid", "mice", "plotly", "viridis")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

imputed_df <- readRDS("data/imputed_dataset_clust.rds")
imputed_df_no_fct <- readRDS("data/imputed_dataset_clust_no_fct.rds")

# Function to determine mode of a vector
getmode <- function(v) {
 uniqv <- unique(v)
 uniqv[which.max(tabulate(match(v, uniqv)))]
}

```

```{r}
# Determine optimal number of cluster using 5 algoritms across 5 imputed datasets
# These algorithms are compatible with Gower's distance method, which is preferred
# for mixed data
indexes <- c("frey", "mcclain", "cindex", "silhouette", "dunn")

for (o in seq_len(imputed_df$m)) {
  
  if (file.exists("data/nr_clust.rds")) {
    nr_clust <- readRDS("data/nr_clust.rds") 
  } else {
    nr_clust <- vector(mode = "list", length = imputed_df$m)
}
  matrix_subset <- complete(imputed_df, o)
  
  distance_matrix <- daisy(matrix_subset, metric = "gower")
  
 for (i in seq_along(indexes)) {
  
  set.seed(4167)
  nr_clust[[o]][indexes[i]] <- NbClust(diss = distance_matrix, distance = NULL, min.nc = 2, method = "median", index = indexes[i])[["Best.nc"]][["Number_clusters"]]

 }
  saveRDS(nr_clust, "data/nr_clust.rds")
}
```

```{r}
# Use visual methods as well - the "elbow" method

eval_methods <- c("wss")

for (o in seq_len(imputed_df$m)) {
  
  if (file.exists("data/nr_clust_viz.rds")) {
    nr_clust <- readRDS("data/nr_clust_viz.rds") 
  } else {
    nr_clust <- vector(mode = "list", length = imputed_df$m)
  }
  
  distance_matrix <- daisy(head(complete(imputed_df, o), 500), metric = "gower")
  matrix_subset <- head(scale(complete(imputed_df_no_fct, o)), 500)
  
 for (i in seq_along(eval_methods)) {
  
  set.seed(4167)
  nr_clust[[o]][[eval_methods[i]]] <- fviz_nbclust(x = matrix_subset, FUNcluster = pam, diss = distance_matrix, verbose = TRUE, method = eval_methods[i], k.max = 15)

 } 
  
  saveRDS(nr_clust, "data/nr_clust_viz.rds")
}

```




```{r}
# Two clusters as a recommended number seems to win with every imputed dataset

optimal_nr_of_clusters <- readRDS("data/nr_clust.rds") %>% bind_rows() %>% rowwise() %>% mutate(mode_of_all = getmode(c(frey, mcclain, cindex, silhouette, dunn)))

```

```{r}
# Run cluster analysis using k-medoids for each of the 5 imputed datasets
list_imp_dfs <- complete(imputed_df, action = "all", include = "FALSE")
list_imp_dfs_no_fct <- complete(imputed_df_no_fct, action = "all", include = "FALSE")
list_cl_dfs <- vector(mode = "list", length = imputed_df$m)
nr_clust <- 14

for (i in seq_len(imputed_df$m)) {
  
  # Calculate the matrix of distance
  distance_matrix_gower <- daisy(list_imp_dfs[[i]], metric = "gower")
  # Cluster with PAM algorithm
  set.seed(4167)
  pam_clust <- pam(distance_matrix_gower, nr_clust, diss = TRUE)

list_cl_dfs[[i]] <- list_imp_dfs_no_fct[[i]] %>%
  scale() %>%
  as_tibble() %>%
  bind_cols(cluster = pam_clust$clustering) %>% 
  pivot_longer(cols = !cluster, names_to = "variable", values_to = "value")

}

saveRDS(list_cl_dfs, "data/list_clustered_dfs_14.rds")
```


```{r}
# Pool imputed datasets together

list_cl_dfs <- readRDS("data/list_clustered_dfs.rds")

pooled_df_2 <- tibble(variable = list_cl_dfs[[1]][[2]],
             value = rowMeans(cbind(list_cl_dfs[[1]][[3]], list_cl_dfs[[2]][[3]], list_cl_dfs[[3]][[3]], list_cl_dfs[[4]][[3]], list_cl_dfs[[5]][[3]])),
             cluster = tibble(df_1 = list_cl_dfs[[1]][[1]], df_2 = list_cl_dfs[[2]][[1]], df_3 = list_cl_dfs[[3]][[1]], df_4 = list_cl_dfs[[4]][[1]], df_5 = list_cl_dfs[[5]][[1]]) %>%
             rowwise() %>% 
             transmute(mode_of_all = getmode(c(df_1, df_2, df_3, df_4, df_5))) %>%
             pull(mode_of_all)
)

list_cl_dfs <- readRDS("data/list_clustered_dfs_3.rds")

pooled_df_3 <- tibble(variable = list_cl_dfs[[1]][[2]],
             value = rowMeans(cbind(list_cl_dfs[[1]][[3]], list_cl_dfs[[2]][[3]], list_cl_dfs[[3]][[3]], list_cl_dfs[[4]][[3]], list_cl_dfs[[5]][[3]])),
             cluster = tibble(df_1 = list_cl_dfs[[1]][[1]], df_2 = list_cl_dfs[[2]][[1]], df_3 = list_cl_dfs[[3]][[1]], df_4 = list_cl_dfs[[4]][[1]], df_5 = list_cl_dfs[[5]][[1]]) %>%
             rowwise() %>% 
             transmute(mode_of_all = getmode(c(df_1, df_2, df_3, df_4, df_5))) %>%
             pull(mode_of_all)
)

list_cl_dfs <- readRDS("data/list_clustered_dfs_14.rds")

pooled_df_14 <- tibble(variable = list_cl_dfs[[1]][[2]],
             value = rowMeans(cbind(list_cl_dfs[[1]][[3]], list_cl_dfs[[2]][[3]], list_cl_dfs[[3]][[3]], list_cl_dfs[[4]][[3]], list_cl_dfs[[5]][[3]])),
             cluster = tibble(df_1 = list_cl_dfs[[1]][[1]], df_2 = list_cl_dfs[[2]][[1]], df_3 = list_cl_dfs[[3]][[1]], df_4 = list_cl_dfs[[4]][[1]], df_5 = list_cl_dfs[[5]][[1]]) %>%
             rowwise() %>% 
             transmute(mode_of_all = getmode(c(df_1, df_2, df_3, df_4, df_5))) %>%
             pull(mode_of_all)
)

```


```{r, message=FALSE, warning=FALSE}
# Cluster visualization for 2 clusters

(ggplot(pooled_df_2, aes(x = variable, y = value, group = as.factor(cluster), colour = as.factor(cluster))) +
  stat_summary(geom = "point",
               fun = mean,
               size = 3
               # aes(shape = cluster)
               ) +
  stat_summary(geom = "line", fun = mean) +
  scale_color_viridis(discrete = TRUE) +
  ggtitle("Average value of selected variables per cluster") +
  theme_bw() +
  ylab("relative value")) %>% ggplotly()

```

```{r, message=FALSE, warning=FALSE}
# Cluster visualization for 3 clusters

(ggplot(pooled_df_3, aes(x = variable, y = value, group = as.factor(cluster), colour = as.factor(cluster))) +
  stat_summary(geom = "point",
               fun = mean,
               size = 3
               # aes(shape = cluster)
               ) +
  stat_summary(geom = "line", fun = mean) +
  scale_color_viridis(discrete = TRUE) +
  ggtitle("Average value of selected variables per cluster") +
  theme_bw() +
  ylab("relative value")) %>% ggplotly()

```

```{r, message=FALSE, warning=FALSE}
# Cluster visualization for 3 clusters

(ggplot(pooled_df_14, aes(x = variable, y = value, group = as.factor(cluster), colour = as.factor(cluster))) +
  stat_summary(geom = "point",
               fun = mean,
               size = 3
               # aes(shape = cluster)
               ) +
  stat_summary(geom = "line", fun = mean) +
  scale_color_viridis(discrete = TRUE) +
  ggtitle("Average value of selected variables per cluster") +
  theme_bw() +
  ylab("relative value")) %>% ggplotly()

```





```{r, message=FALSE, warning=FALSE}
# # identify all factor columns
# x <- sapply(matrix_subset, is.factor)
# matrix_subset[ , x] <- sapply(matrix_subset[ , x], MARGIN = 2, as.numeric)
# matrix_subset <- sapply(matrix_subset, as.integer) %>% scale()

# Calculate the matrix of distance, we can choose from many methods

fviz_dist(distance_matrix, gradient = list(low = "blue", mid = "white", high = "red"))

fviz_nbclust(resnumclust)


fviz_cluster(pam3, data = matrix_subset, ellipse.type = "norm", ggtheme = theme_bw(), main = "Cluster plot - K-Medoids algorithm")
```


```{r, message=FALSE, warning=FALSE}
# Cluster validation

intern <- clValid(matrix_subset,
                  nClust = 2:15,
                  clMethods = c("hierarchical", "kmeans", "pam"),
                  validation = c("internal", "stability"))

summary(intern) %>% kable() %>% kable_styling()

```



